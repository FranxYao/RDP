{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dafab29-1d67-4431-bdc8-d27a22abd44a",
   "metadata": {},
   "source": [
    "# Align bigram with existing annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "80573f2b-2c4e-4020-a3b2-ca46f8a1466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from tokenizations import get_alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0361a49-a81e-411b-8806-900ff0decb3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633e8364-25c3-43bc-aaa5-b413a77f155a",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9493d660-f832-4bbf-b8fe-040913a63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(datapath):\n",
    "    data = open(datapath).readlines()\n",
    "    states = []\n",
    "    words = []\n",
    "    word_idx = []\n",
    "    for li, l in enumerate(data):\n",
    "        if(li % 3 == 0): word_idx.append([int(w) for w in l.split()])\n",
    "        elif(li % 3 == 1): states.append([int(z) for z in l.split()])\n",
    "        else: words.append(l.split())\n",
    "    return words, states, word_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1f7947-5e4e-4737-8c83-13edfc8fb501",
   "metadata": {},
   "outputs": [],
   "source": [
    "words, states, word_idx = read_data('bertnet_0.0.6.4_dev_epoch_-1_state_seq.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0894bf43-8eab-4614-a438-61bcacd2912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7de5c294-19b4-4a4f-9aee-c96257ae388d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 23)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(states[0]), len(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d92ef723-1a05-45b4-b3b2-ecd4b308369a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', \"'\", 're', 'right', ',', '\"', 'the', 'bottom', 'line', 'is', 'truth', ',', '\"', 'ind', '##ep', '##end', '##ant', 'from', 'you', 'or', 'anyone', 'else', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b85f835-9eb6-4faa-9dcc-f639c1471558",
   "metadata": {},
   "source": [
    "## Convert Bert tokenized to spacy tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b62e6998-b045-4181-914a-b679b358c28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_to_spacy_all = pickle.load(open('bert_to_spacy.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "95453f03-898b-4117-9bc9-fc1fc5c12186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_state(bert2spacy, tags):\n",
    "    prev_spacy_idx = -1\n",
    "    tags_converted = []\n",
    "    assert(len(bert2spacy) == len(tags)) # make sure pre-stored data matches the dev data\n",
    "    for bi, (si_, t) in enumerate(zip(bert2spacy, tags)):\n",
    "        for si in si_:\n",
    "            assert(si == prev_spacy_idx or si == prev_spacy_idx + 1) # every spacy token should be aligned\n",
    "            # if many consequtive BERT token correspond to the same spacy token, \n",
    "            # then only use the tag for the first bert token\n",
    "            if(si == prev_spacy_idx + 1): \n",
    "                prev_spacy_idx += 1\n",
    "                tags_converted.append(t)\n",
    "    return tags_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e35e3b7-0b5d-4529-bfef-526867ea82cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_to_spacy_convert(latent_tags, bert_to_spacy_all):\n",
    "    ## convert a tag seq upon bert-tokenized to spacy-tokenized\n",
    "    latent_tags_spacy = []\n",
    "    assert(len(bert_to_spacy_all) == len(latent_tags))\n",
    "    for bert2spacy, tags in tqdm(zip(bert_to_spacy_all, latent_tags)):\n",
    "        prev_spacy_idx = -1\n",
    "        tags_converted = []\n",
    "        assert(len(bert2spacy) == len(tags)) # make sure pre-stored data matches the dev data\n",
    "        for bi, (si_, t) in enumerate(zip(bert2spacy, tags)):\n",
    "            for si in si_:\n",
    "                assert(si == prev_spacy_idx or si == prev_spacy_idx + 1)\n",
    "                # if many consequtive BERT token correspond to the same spacy token, \n",
    "                # then only use the tag for the first bert token\n",
    "                if(si == prev_spacy_idx + 1): \n",
    "                    prev_spacy_idx += 1\n",
    "                    tags_converted.append(t)\n",
    "        latent_tags_spacy.append(tags_converted)\n",
    "    return latent_tags_spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a59de48-4767-42c1-8e84-cfb73dd0ff21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26121it [00:00, 126802.09it/s]\n"
     ]
    }
   ],
   "source": [
    "states_spacy = bert_to_spacy_convert(states, bert_to_spacy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0ed6dc4-91d4-4331-9530-8b0c2bbe8261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[772, 1359, 1529, 344, 465, 1532, 681, 681, 1874, 1445, 1602, 465, 1532, 445, 445, 445, 426, 369, 1045, 1138, 128, 128, 64]\n",
      "[772, 1359, 344, 465, 1532, 681, 681, 1874, 1445, 1602, 465, 1532, 445, 369, 1045, 1138, 128, 128, 64]\n"
     ]
    }
   ],
   "source": [
    "print(states[0])\n",
    "print(states_spacy[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b54296-428f-44ba-8d7f-d07ead1a40cf",
   "metadata": {},
   "source": [
    "# Open IE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d7f0efb-2ac2-44a7-bd38-033f436361c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openie_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8d625a7e-13e3-4bf8-9b08-403a1d827357",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = openie_predictor.predict(tokenizer.convert_tokens_to_string(words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75c697d0-6520-4c99-817c-5e0ee1b69b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['verbs', 'words'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "743fff84-3251-43ed-8afe-6513d7fbd072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d071879-7f81-4c43-936b-8ae09ae1a0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.convert_tokens_to_string(words[0]).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e1814a8-ece8-4ffa-bd29-563bf4524216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "460e1dd5-02d7-4070-8586-3ecd21131894",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_to_spacy, _ = get_alignments(words[0], out['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "83c7471a-0481-4a4d-9e57-5d039e23910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = convert_tag(bert_to_spacy, states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e31cea1-59c3-4ea5-be9b-07bbf6128fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c7411856-1050-4667-9de6-4b328ab0c5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:13<00:00,  7.57it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    states_openie = []\n",
    "    tags_openie = []\n",
    "    for w, s in tqdm(list(zip(words[:100], states[:100]))):\n",
    "        out = openie_predictor.predict(tokenizer.convert_tokens_to_string(w))\n",
    "        tags_openie.append(out['verbs'])\n",
    "        bert_to_spacy, _ = get_alignments(w, out['words'])\n",
    "        s_ = convert_state(bert_to_spacy, s)\n",
    "        states_openie.append(s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "832d36f9-bfab-4369-a7d7-79aaef836105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(tags_openie, open('tags_openie.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f7760eb9-2b97-443e-b8fc-aeea4c154389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pickle.dump(states_openie, open('states_openie.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b5f57-9307-485d-9bcf-ee13a9806948",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each bigram, construct a bigram - IE tag dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7e6d86-f8df-497a-a586-9a94a1aa8f6f",
   "metadata": {},
   "source": [
    "# SRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b35ced0-c71e-4637-bfd6-0c5fbc9b2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "srl_predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad6a080-a42e-40fc-b5c0-f0edb2531ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For each bigram, construct a bigram - SRL tag dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99917b3-3cd7-4f5b-8d36-f69d3eb22297",
   "metadata": {},
   "source": [
    "# Constituency\n",
    "\n",
    "For each bigram, construct a bigram - SRL tag dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c426ab00-465b-479f-bdc6-074d56351cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yaofu/miniconda3/envs/dl_py3.7/lib/python3.7/site-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
     ]
    }
   ],
   "source": [
    "parser = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/elmo-constituency-parser-2020.02.10.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a84b5276-1e43-4b45-90ac-13b320285c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_batch_json_to_instances',\n",
       " '_build_hierplane_tree',\n",
       " '_dataset_reader',\n",
       " '_json_to_instance',\n",
       " '_model',\n",
       " '_register_embedding_gradient_hooks',\n",
       " '_registry',\n",
       " '_token_offsets',\n",
       " '_tokenizer',\n",
       " 'by_name',\n",
       " 'capture_model_internals',\n",
       " 'cuda_device',\n",
       " 'default_implementation',\n",
       " 'dump_line',\n",
       " 'from_archive',\n",
       " 'from_params',\n",
       " 'from_path',\n",
       " 'get_gradients',\n",
       " 'get_interpretable_layer',\n",
       " 'get_interpretable_text_field_embedder',\n",
       " 'json_to_labeled_instances',\n",
       " 'list_available',\n",
       " 'load_line',\n",
       " 'predict',\n",
       " 'predict_batch_instance',\n",
       " 'predict_batch_json',\n",
       " 'predict_instance',\n",
       " 'predict_json',\n",
       " 'predictions_to_labeled_instances',\n",
       " 'register',\n",
       " 'resolve_class_name']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1388cf4-0855-4efc-805b-f2cfe354e41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = parser.predict(\n",
    "    sentence=\"If you bring $10 with you tomorrow, can you pay for me to eat too?.\".lower()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ccccbad2-d941-494a-b612-1f8dae7479fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['word', 'nodeType', 'attributes', 'link', 'children'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['hierplane_tree']['root']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd7565fb-390f-4449-9f75-efc6fe183f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if you bring $ 10 with you tomorrow , can you pay for me to eat too ? .'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['hierplane_tree']['root']['word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d122d9d8-ff9a-4300-99e3-8d31ba4be76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SQ']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['hierplane_tree']['root']['attributes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "caef9ee3-beda-4d45-9ef6-9d78b895d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traversal(root):\n",
    "    q = [root]\n",
    "    out = []\n",
    "    while(len(q) > 0):\n",
    "        node = q[0]\n",
    "        q = q[1:]\n",
    "        # print(node['word'])\n",
    "        if(len(node['word'].split()) == 2):\n",
    "            out.append((node['word'], node['attributes']))\n",
    "        if('children' in node):\n",
    "            for c in node['children']: q.append(c)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e42385f-7d69-45f9-b6eb-a20c75ecb939",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = traversal(out['hierplane_tree']['root'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "636eb0ca-698c-4ac7-8132-357309c72d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('$ 10', ['NP']), ('with you', ['PP']), ('eat too', ['VP'])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
