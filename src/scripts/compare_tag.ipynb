{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "brilliant-separate",
   "metadata": {},
   "source": [
    "# Comparing the overlap between inferred tags with a supervised tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "twelve-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import codecs\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "from tokenizations import get_alignments\n",
    "from transformers import BertTokenizer\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "municipal-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path='../../data/news/'):\n",
    "    \"\"\"Read 20news data, train only\"\"\"\n",
    "    # use the cased data for NER, otherwise spacy does not work with uncased \n",
    "    with codecs.open(data_path + '20news_cased.txt', encoding='utf-8') as fd:\n",
    "        data = fd.readlines()\n",
    "    train_idx = np.load(data_path + 'train_index.npy')\n",
    "    train_data = [data[i][: -1] for i in train_idx]\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "municipal-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "outstanding-archive",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dict = {}\n",
    "ent_dict = {}\n",
    "token_bert2spacy = {}\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable='parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "czech-cable",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:00<00:00, 165.43it/s]\n"
     ]
    }
   ],
   "source": [
    "for s in tqdm(train_data[:10000]):\n",
    "    doc = nlp(s)\n",
    "\n",
    "    spacy_tokenized = []\n",
    "    for token in doc:\n",
    "        if(token.pos_ not in pos_dict):\n",
    "            pos_dict[token.pos_] = [token.text]\n",
    "        else:\n",
    "            pos_dict[token.pos_].append(token.text)\n",
    "            spacy_tokenized.append(token.text)\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if(ent.label_ not in ent_dict): ent_dict[ent.label_] = [ent.text]\n",
    "        else: ent_dict[ent.label_].append(ent.text)\n",
    "\n",
    "    bert_tokenized = tokenizer.tokenize(s)\n",
    "\n",
    "    bert2spacy, spacy2bert = get_alignments(bert_tokenized, spacy_tokenized)\n",
    "    for w, w_ in enumerate(bert2spacy):\n",
    "        w = bert_tokenized[w]\n",
    "        if(w not in token_bert2spacy):\n",
    "            token_bert2spacy[w] = []\n",
    "        for wi in w_:\n",
    "            token_bert2spacy[w].append(spacy_tokenized[wi])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "gorgeous-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pos_dict:\n",
    "    pos_dict[p] = Counter(pos_dict[p])\n",
    "    \n",
    "for e in ent_dict:\n",
    "    ent_dict[e] = Counter(ent_dict[e])\n",
    "    \n",
    "for w in token_bert2spacy:\n",
    "    token_bert2spacy[w] = Counter(token_bert2spacy[w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "municipal-childhood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 18 13398\n"
     ]
    }
   ],
   "source": [
    "print(len(pos_dict), len(ent_dict), len(token_bert2spacy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "mature-wednesday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['VERB', 'PRON', 'AUX', 'DET', 'ADJ', 'NOUN', 'PUNCT', 'PROPN', 'ADV', 'SCONJ', 'ADP', 'PART', 'CCONJ', 'SYM', 'NUM', 'INTJ', 'X'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "strategic-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ORG', 'DATE', 'PRODUCT', 'NORP', 'PERSON', 'CARDINAL', 'GPE', 'TIME', 'ORDINAL', 'LAW', 'QUANTITY', 'WORK_OF_ART', 'LANGUAGE', 'MONEY', 'FAC', 'EVENT', 'LOC', 'PERCENT'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-store",
   "metadata": {},
   "source": [
    "# Read state-word dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "monetary-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = {}\n",
    "state_freq = {}\n",
    "with codecs.open('../../local/bertnet_0.0.4.10.4_stored/bertnet_dev_epoch_17_s2w.txt', encoding='utf-8') as fd:\n",
    "    lines = fd.readlines()\n",
    "    for li, l in enumerate(lines):\n",
    "        if(l.startswith('state') and li %3 == 0):\n",
    "            l = l[:-1].split()\n",
    "            state_id = l[1]\n",
    "            freq = l[3]\n",
    "            freq_no_sw = l[5]\n",
    "            state_freq[state_id] = {'freq': float(freq), 'freq_no_sw': float(freq_no_sw)}\n",
    "            state_dict[state_id] = []\n",
    "        elif(lines[li - 1].startswith('state')):\n",
    "            words = l.split(' | ')\n",
    "            for w in words[:-1]:\n",
    "                w = w.split()\n",
    "#                 print(w)\n",
    "                state_dict[state_id].append((w[0], float(w[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-pregnancy",
   "metadata": {},
   "source": [
    "## Measurement of alignment 1, dominate word set\n",
    "* Definition: W(s) 95% dominate word set = the set of words that account for the 95% of state / POS vocab.\n",
    "* if W(s) \\in W(POS) we say s align with a pos\n",
    "\n",
    "## Measurement of alignment 2, word occurance \n",
    "* If 50% of state word occurance exist in a POS dominate set, then view this as an alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recognized-organization",
   "metadata": {},
   "source": [
    "## Implementation of dominate word set alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "classified-genealogy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1351 non stop states\n"
     ]
    }
   ],
   "source": [
    "# find non stop states \n",
    "\n",
    "non_sw_states = []\n",
    "for s in state_freq: \n",
    "    if(state_freq[s]['freq_no_sw'] / float(state_freq[s]['freq']) > 0.5):\n",
    "        non_sw_states.append(s)\n",
    "print('%d non stop states' % len(non_sw_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "prostate-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['171', '476', '710', '254', '1419', '1972', '403', '1488', '1556', '243']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sw_states[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "killing-prophet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each non-SW state, calculate their 95% vocab\n",
    "\n",
    "state_dominate_set = {}\n",
    "for s in non_sw_states:\n",
    "    freq = state_freq[s]['freq']\n",
    "    wf_cumu = 0\n",
    "    state_dominate_set[s] = []\n",
    "    for w, wf in state_dict[s]:\n",
    "        wf_cumu += wf\n",
    "        if(wf_cumu / freq < 0.9): \n",
    "            state_dominate_set[s].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "least-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove subwords clusters\n",
    "\n",
    "def test_subword_cluster(wset):\n",
    "    \"\"\"if half of the cluster is subwords, then this is a subword cluster\"\"\"\n",
    "    set_len = len(wset)\n",
    "    num_subwords = 0\n",
    "    for w in wset:\n",
    "        if(w.startswith('##')): num_subwords += 1\n",
    "        if(len(w) <= 2): num_subwords += 1\n",
    "    if(num_subwords > set_len // 2): return True\n",
    "    else: return False\n",
    "    \n",
    "non_sw_states = []\n",
    "for s in state_dominate_set:\n",
    "    if(test_subword_cluster(state_dominate_set[s])): pass\n",
    "    else: non_sw_states.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "manual-alias",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1060"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_sw_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "disciplinary-newman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert dominate set to gpt2 tokenization\n",
    "\n",
    "state_dominate_set_gpt_token = {}\n",
    "for s in non_sw_states:\n",
    "    w_ = []\n",
    "    for w in state_dominate_set[s]:\n",
    "        if(w in token_bert2spacy):\n",
    "            spacy_tokens_w = token_bert2spacy[w].keys()\n",
    "            spacy_tokens_w = set([t.lower() for t in spacy_tokens_w])\n",
    "            w_.extend(list(spacy_tokens_w))\n",
    "        else: w_.append(w)\n",
    "    state_dominate_set_gpt_token[s] = set(w_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "automated-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['476', '710', '254', '1419', '1972', '403', '1488', '1556', '243', '1410']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_sw_states[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "potential-tomorrow",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abuse',\n",
       " 'accident',\n",
       " 'attack',\n",
       " 'attacks',\n",
       " 'bad',\n",
       " 'badanes',\n",
       " 'badatom',\n",
       " 'badcolor',\n",
       " 'badertscher',\n",
       " 'badfont',\n",
       " 'conflict',\n",
       " 'crash',\n",
       " 'crime',\n",
       " 'crimes',\n",
       " 'crimestrike',\n",
       " 'criminals',\n",
       " 'damage',\n",
       " 'dangerous',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'deathbed',\n",
       " 'deaths',\n",
       " 'destroyed',\n",
       " 'destruction',\n",
       " 'die',\n",
       " 'died',\n",
       " 'disease',\n",
       " 'error',\n",
       " 'errors',\n",
       " 'evil',\n",
       " 'failure',\n",
       " 'fault',\n",
       " 'genocide',\n",
       " 'harm',\n",
       " 'harming',\n",
       " 'hate',\n",
       " 'hateful',\n",
       " 'hatred',\n",
       " 'hell',\n",
       " 'hellish',\n",
       " 'hellman',\n",
       " 'hit',\n",
       " 'hite',\n",
       " 'hiten',\n",
       " 'hurt',\n",
       " 'incident',\n",
       " 'incidental',\n",
       " 'incidentally',\n",
       " 'injury',\n",
       " \"is'wrong\",\n",
       " \"jesus'death\",\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'killing',\n",
       " \"like'crime\",\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lossless',\n",
       " 'lossy',\n",
       " 'lost',\n",
       " \"makedepend'problem\",\n",
       " 'massacre',\n",
       " 'massacred',\n",
       " 'massacres',\n",
       " 'mistake',\n",
       " 'murder',\n",
       " 'murdered',\n",
       " 'murders',\n",
       " 'pain',\n",
       " 'painless',\n",
       " 'penalty',\n",
       " \"pitchers'bad\",\n",
       " 'problem',\n",
       " 'problems',\n",
       " 'punish',\n",
       " 'punishable',\n",
       " 'punishes',\n",
       " 'punishing',\n",
       " 'punishment',\n",
       " 'sick',\n",
       " 'sickens',\n",
       " 'sin',\n",
       " 'sin66',\n",
       " 'sinauer',\n",
       " 'sinful',\n",
       " 'sinless',\n",
       " 'sinus',\n",
       " 'sinuses',\n",
       " 'sorry',\n",
       " 'suicide',\n",
       " 'trouble',\n",
       " 'troublemaker',\n",
       " 'violence',\n",
       " 'worse',\n",
       " 'worsen',\n",
       " 'worst',\n",
       " 'wrong',\n",
       " 'wrongful',\n",
       " 'wrongness'}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dominate_set_gpt_token['710']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "roman-roommate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dominate set size for VERB = 2405\n",
      "dominate set size for PRON = 33\n",
      "dominate set size for AUX = 29\n",
      "dominate set size for DET = 16\n",
      "dominate set size for ADJ = 1520\n",
      "dominate set size for NOUN = 5183\n",
      "dominate set size for PUNCT = 8\n",
      "dominate set size for PROPN = 4711\n",
      "dominate set size for ADV = 389\n",
      "dominate set size for SCONJ = 14\n",
      "dominate set size for ADP = 28\n",
      "dominate set size for PART = 3\n",
      "dominate set size for CCONJ = 6\n",
      "dominate set size for SYM = 4\n",
      "dominate set size for NUM = 603\n",
      "dominate set size for INTJ = 108\n",
      "dominate set size for X = 69\n"
     ]
    }
   ],
   "source": [
    "# calculate 95% vocab of POS \n",
    "\n",
    "pos_dominate_set = {}\n",
    "\n",
    "for p in pos_dict:\n",
    "    full_occ = float(sum(c for w, c in pos_dict[p].most_common()))\n",
    "    wf_cumu = 0\n",
    "    wset = []\n",
    "    for w, c in pos_dict[p].most_common():\n",
    "        wf_cumu += c\n",
    "        if(wf_cumu / full_occ < 0.95): wset.append(w.lower())\n",
    "    pos_dominate_set[p] = set(wset)\n",
    "    print('dominate set size for %s = %d' % (p, len(wset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "southwest-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dominate_set_gpt_token['243'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "standard-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state_dominate_set_gpt_token['243'].intersection(pos_dominate_set['ADV']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "individual-privacy",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state 710 aligned with POS NOUN, overlap 0.51\n",
      "state 254 aligned with POS PROPN, overlap 0.73\n",
      "state 403 aligned with POS PROPN, overlap 0.58\n",
      "state 1488 aligned with POS ADJ, overlap 0.61\n",
      "state 1410 aligned with POS ADJ, overlap 0.56\n",
      "state 555 aligned with POS NOUN, overlap 0.55\n",
      "state 865 aligned with POS NOUN, overlap 0.53\n",
      "state 1572 aligned with POS PROPN, overlap 0.56\n",
      "state 1683 aligned with POS NOUN, overlap 0.55\n",
      "state 1584 aligned with POS PROPN, overlap 0.53\n",
      "state 1643 aligned with POS NOUN, overlap 0.60\n",
      "state 1966 aligned with POS PROPN, overlap 0.72\n",
      "state 1656 aligned with POS NOUN, overlap 0.65\n",
      "state 1702 aligned with POS NOUN, overlap 0.63\n",
      "state 603 aligned with POS PROPN, overlap 0.51\n",
      "state 1874 aligned with POS PROPN, overlap 0.53\n",
      "state 1181 aligned with POS NOUN, overlap 0.56\n",
      "state 1973 aligned with POS NOUN, overlap 0.69\n",
      "state 202 aligned with POS PROPN, overlap 0.60\n",
      "state 1022 aligned with POS PROPN, overlap 0.62\n",
      "state 1183 aligned with POS PROPN, overlap 0.69\n",
      "state 1142 aligned with POS VERB, overlap 0.57\n",
      "state 1451 aligned with POS PROPN, overlap 0.55\n",
      "state 1816 aligned with POS VERB, overlap 0.75\n",
      "state 1477 aligned with POS PROPN, overlap 0.52\n",
      "state 1004 aligned with POS PROPN, overlap 0.61\n",
      "state 911 aligned with POS PROPN, overlap 0.52\n",
      "state 1126 aligned with POS PROPN, overlap 0.62\n",
      "state 1276 aligned with POS PROPN, overlap 0.51\n",
      "state 1392 aligned with POS PROPN, overlap 0.51\n",
      "state 739 aligned with POS PROPN, overlap 0.52\n",
      "state 4 aligned with POS PROPN, overlap 0.54\n",
      "state 699 aligned with POS PROPN, overlap 0.56\n",
      "state 1924 aligned with POS PROPN, overlap 0.56\n",
      "state 884 aligned with POS PROPN, overlap 0.51\n",
      "state 1940 aligned with POS PROPN, overlap 0.52\n",
      "state 1598 aligned with POS PROPN, overlap 0.56\n",
      "state 116 aligned with POS PROPN, overlap 0.55\n",
      "state 1347 aligned with POS PROPN, overlap 0.51\n",
      "state 1947 aligned with POS PROPN, overlap 0.55\n",
      "state 1581 aligned with POS PROPN, overlap 0.55\n",
      "state 765 aligned with POS PROPN, overlap 0.53\n",
      "state 327 aligned with POS PROPN, overlap 0.54\n",
      "state 1593 aligned with POS PROPN, overlap 0.53\n",
      "state 105 aligned with POS PROPN, overlap 0.52\n",
      "state 1645 aligned with POS PROPN, overlap 0.51\n",
      "state 1404 aligned with POS PROPN, overlap 0.58\n",
      "state 1373 aligned with POS PROPN, overlap 0.53\n",
      "state 920 aligned with POS PROPN, overlap 0.54\n",
      "state 873 aligned with POS PROPN, overlap 0.56\n",
      "state 22 aligned with POS PROPN, overlap 0.52\n",
      "state 1708 aligned with POS PROPN, overlap 0.58\n",
      "state 197 aligned with POS PROPN, overlap 0.54\n",
      "state 1144 aligned with POS PROPN, overlap 0.56\n",
      "state 985 aligned with POS PROPN, overlap 0.51\n",
      "state 893 aligned with POS PROPN, overlap 0.51\n",
      "state 1157 aligned with POS PROPN, overlap 0.54\n",
      "state 1502 aligned with POS PROPN, overlap 0.51\n",
      "state 1835 aligned with POS PROPN, overlap 0.56\n",
      "state 1769 aligned with POS PROPN, overlap 0.59\n",
      "state 1102 aligned with POS PROPN, overlap 0.52\n",
      "state 1864 aligned with POS PROPN, overlap 0.53\n",
      "state 446 aligned with POS PROPN, overlap 0.59\n",
      "state 297 aligned with POS PROPN, overlap 0.55\n",
      "state 1580 aligned with POS PROPN, overlap 0.60\n",
      "state 738 aligned with POS PROPN, overlap 0.56\n",
      "state 1333 aligned with POS PROPN, overlap 0.52\n",
      "state 1971 aligned with POS PROPN, overlap 0.51\n",
      "state 1536 aligned with POS PROPN, overlap 0.57\n",
      "state 1114 aligned with POS PROPN, overlap 0.52\n",
      "state 1466 aligned with POS PROPN, overlap 0.56\n",
      "state 790 aligned with POS PROPN, overlap 0.58\n",
      "state 23 aligned with POS PROPN, overlap 0.62\n",
      "state 542 aligned with POS PROPN, overlap 0.51\n",
      "state 199 aligned with POS PROPN, overlap 0.52\n",
      "state 1664 aligned with POS PROPN, overlap 0.56\n",
      "state 672 aligned with POS PROPN, overlap 0.52\n",
      "state 139 aligned with POS PROPN, overlap 0.58\n",
      "state 130 aligned with POS PROPN, overlap 0.57\n",
      "state 68 aligned with POS PROPN, overlap 0.61\n",
      "state 1355 aligned with POS PROPN, overlap 0.53\n",
      "state 15 aligned with POS PROPN, overlap 0.60\n",
      "state 1311 aligned with POS PROPN, overlap 0.51\n",
      "state 1481 aligned with POS PROPN, overlap 0.57\n",
      "state 209 aligned with POS PROPN, overlap 0.56\n",
      "state 1143 aligned with POS PROPN, overlap 0.55\n",
      "state 1178 aligned with POS PROPN, overlap 0.53\n",
      "state 540 aligned with POS PROPN, overlap 0.56\n",
      "state 810 aligned with POS PROPN, overlap 0.58\n",
      "state 1487 aligned with POS PROPN, overlap 0.55\n",
      "state 690 aligned with POS PROPN, overlap 0.60\n",
      "state 901 aligned with POS PROPN, overlap 0.53\n",
      "state 61 aligned with POS PROPN, overlap 0.52\n",
      "state 200 aligned with POS PROPN, overlap 0.51\n",
      "state 846 aligned with POS PROPN, overlap 0.58\n",
      "state 1067 aligned with POS PROPN, overlap 0.51\n",
      "state 1169 aligned with POS PROPN, overlap 0.56\n",
      "state 1573 aligned with POS PROPN, overlap 0.52\n",
      "state 778 aligned with POS PROPN, overlap 0.57\n",
      "state 531 aligned with POS PROPN, overlap 0.58\n",
      "state 108 aligned with POS PROPN, overlap 0.54\n",
      "state 1567 aligned with POS PROPN, overlap 0.52\n",
      "state 1495 aligned with POS PROPN, overlap 0.51\n",
      "state 1162 aligned with POS PROPN, overlap 0.52\n",
      "state 249 aligned with POS PROPN, overlap 0.58\n",
      "state 1051 aligned with POS PROPN, overlap 0.52\n",
      "state 1960 aligned with POS PROPN, overlap 0.51\n",
      "state 1876 aligned with POS PROPN, overlap 0.51\n",
      "state 1766 aligned with POS PROPN, overlap 0.56\n",
      "state 953 aligned with POS PROPN, overlap 0.60\n",
      "state 963 aligned with POS PROPN, overlap 0.51\n",
      "state 946 aligned with POS PROPN, overlap 0.55\n",
      "state 602 aligned with POS PROPN, overlap 0.52\n",
      "state 607 aligned with POS PROPN, overlap 0.54\n",
      "state 730 aligned with POS PROPN, overlap 0.57\n",
      "state 1331 aligned with POS PROPN, overlap 0.56\n",
      "state 1332 aligned with POS PROPN, overlap 0.59\n",
      "state 991 aligned with POS PROPN, overlap 0.51\n",
      "state 1688 aligned with POS PROPN, overlap 0.54\n",
      "state 332 aligned with POS PROPN, overlap 0.50\n",
      "state 1906 aligned with POS PROPN, overlap 0.59\n",
      "state 1834 aligned with POS PROPN, overlap 0.58\n",
      "state 1741 aligned with POS PROPN, overlap 0.54\n",
      "state 947 aligned with POS PROPN, overlap 0.62\n",
      "state 945 aligned with POS PROPN, overlap 0.52\n",
      "state 1322 aligned with POS PROPN, overlap 0.52\n",
      "state 1137 aligned with POS PROPN, overlap 0.54\n",
      "state 784 aligned with POS PROPN, overlap 0.55\n",
      "state 1170 aligned with POS PROPN, overlap 0.60\n",
      "state 1261 aligned with POS PROPN, overlap 0.57\n",
      "state 1232 aligned with POS PROPN, overlap 0.56\n",
      "state 787 aligned with POS PROPN, overlap 0.61\n",
      "state 245 aligned with POS PROPN, overlap 0.54\n",
      "state 1639 aligned with POS PROPN, overlap 0.63\n",
      "state 1652 aligned with POS PROPN, overlap 0.54\n",
      "state 1890 aligned with POS PROPN, overlap 0.59\n",
      "state 42 aligned with POS PROPN, overlap 0.52\n",
      "state 44 aligned with POS PROPN, overlap 0.51\n",
      "state 312 aligned with POS PROPN, overlap 0.57\n",
      "state 318 aligned with POS PROPN, overlap 0.54\n",
      "state 1472 aligned with POS PROPN, overlap 0.52\n",
      "state 998 aligned with POS PROPN, overlap 0.51\n",
      "state 1953 aligned with POS PROPN, overlap 0.59\n",
      "state 732 aligned with POS PROPN, overlap 0.57\n",
      "state 827 aligned with POS PROPN, overlap 0.53\n",
      "state 1307 aligned with POS PROPN, overlap 0.56\n",
      "state 1860 aligned with POS PROPN, overlap 0.55\n",
      "state 20 aligned with POS PROPN, overlap 0.51\n",
      "state 1849 aligned with POS PROPN, overlap 0.58\n",
      "state 916 aligned with POS PROPN, overlap 0.60\n",
      "state 857 aligned with POS PROPN, overlap 0.61\n",
      "state 627 aligned with POS PROPN, overlap 0.51\n",
      "state 1239 aligned with POS PROPN, overlap 0.53\n",
      "state 1750 aligned with POS PROPN, overlap 0.52\n",
      "state 1459 aligned with POS PROPN, overlap 0.58\n",
      "state 573 aligned with POS PROPN, overlap 0.54\n",
      "state 72 aligned with POS PROPN, overlap 0.58\n",
      "state 1289 aligned with POS PROPN, overlap 0.55\n",
      "state 65 aligned with POS PROPN, overlap 0.55\n",
      "state 148 aligned with POS PROPN, overlap 0.60\n",
      "state 980 aligned with POS PROPN, overlap 0.57\n",
      "state 1609 aligned with POS PROPN, overlap 0.55\n",
      "state 1624 aligned with POS PROPN, overlap 0.55\n",
      "state 826 aligned with POS PROPN, overlap 0.54\n",
      "state 817 aligned with POS PROPN, overlap 0.60\n",
      "state 1718 aligned with POS PROPN, overlap 0.53\n",
      "state 1779 aligned with POS PROPN, overlap 0.53\n",
      "state 1824 aligned with POS PROPN, overlap 0.59\n",
      "state 1827 aligned with POS PROPN, overlap 0.53\n",
      "state 1848 aligned with POS PROPN, overlap 0.61\n",
      "state 1076 aligned with POS PROPN, overlap 0.51\n",
      "state 1066 aligned with POS PROPN, overlap 0.54\n",
      "state 1854 aligned with POS PROPN, overlap 0.58\n",
      "state 1272 aligned with POS PROPN, overlap 0.54\n",
      "state 1975 aligned with POS PROPN, overlap 0.55\n",
      "state 527 aligned with POS PROPN, overlap 0.52\n",
      "state 580 aligned with POS PROPN, overlap 0.53\n",
      "state 502 aligned with POS PROPN, overlap 0.51\n",
      "state 133 aligned with POS PROPN, overlap 0.53\n",
      "state 632 aligned with POS PROPN, overlap 0.55\n",
      "state 1527 aligned with POS PROPN, overlap 0.67\n",
      "state 1557 aligned with POS PROPN, overlap 0.64\n",
      "state 436 aligned with POS PROPN, overlap 0.57\n",
      "state 1241 aligned with POS PROPN, overlap 0.61\n",
      "state 1381 aligned with POS PROPN, overlap 0.66\n",
      "state 238 aligned with POS PROPN, overlap 0.57\n",
      "state 1738 aligned with POS PROPN, overlap 0.54\n",
      "state 86 aligned with POS PROPN, overlap 0.56\n",
      "state 340 aligned with POS PROPN, overlap 0.51\n",
      "state 1821 aligned with POS PROPN, overlap 0.56\n",
      "state 796 aligned with POS PROPN, overlap 0.64\n",
      "state 1760 aligned with POS PROPN, overlap 0.63\n",
      "state 3 aligned with POS PROPN, overlap 0.57\n",
      "state 669 aligned with POS PROPN, overlap 0.52\n",
      "state 519 aligned with POS PROPN, overlap 0.51\n",
      "state 1082 aligned with POS PROPN, overlap 0.63\n",
      "state 1001 aligned with POS PROPN, overlap 0.65\n",
      "state 347 aligned with POS PROPN, overlap 0.59\n",
      "state 325 aligned with POS PROPN, overlap 0.54\n",
      "state 1061 aligned with POS PROPN, overlap 0.54\n",
      "state 1285 aligned with POS PROPN, overlap 0.61\n",
      "state 1969 aligned with POS PROPN, overlap 0.57\n",
      "state 1696 aligned with POS PROPN, overlap 0.50\n",
      "state 999 aligned with POS PROPN, overlap 0.56\n",
      "state 311 aligned with POS PROPN, overlap 0.63\n",
      "state 241 aligned with POS PROPN, overlap 0.58\n",
      "state 772 aligned with POS PROPN, overlap 0.52\n",
      "state 259 aligned with POS PROPN, overlap 0.66\n",
      "state 212 aligned with POS PROPN, overlap 0.58\n",
      "state 1014 aligned with POS PROPN, overlap 0.60\n",
      "state 1625 aligned with POS PROPN, overlap 0.56\n",
      "state 922 aligned with POS PROPN, overlap 0.60\n",
      "state 886 aligned with POS PROPN, overlap 0.54\n",
      "state 397 aligned with POS PROPN, overlap 0.65\n",
      "state 532 aligned with POS PROPN, overlap 0.58\n",
      "state 158 aligned with POS PROPN, overlap 0.55\n",
      "state 1176 aligned with POS PROPN, overlap 0.57\n",
      "state 1723 aligned with POS PROPN, overlap 0.60\n",
      "state 1174 aligned with POS PROPN, overlap 0.53\n",
      "state 1219 aligned with POS PROPN, overlap 0.60\n",
      "state 74 aligned with POS PROPN, overlap 0.54\n",
      "state 1036 aligned with POS PROPN, overlap 0.52\n",
      "state 902 aligned with POS PROPN, overlap 0.58\n",
      "state 38 aligned with POS PROPN, overlap 0.60\n",
      "state 1993 aligned with POS PROPN, overlap 0.54\n",
      "state 237 aligned with POS PROPN, overlap 0.54\n",
      "state 337 aligned with POS PROPN, overlap 0.52\n",
      "state 756 aligned with POS PROPN, overlap 0.55\n",
      "state 19 aligned with POS PROPN, overlap 0.62\n",
      "state 1457 aligned with POS PROPN, overlap 0.59\n",
      "state 349 aligned with POS PROPN, overlap 0.62\n",
      "state 1871 aligned with POS PROPN, overlap 0.59\n",
      "state 106 aligned with POS PROPN, overlap 0.63\n",
      "state 755 aligned with POS PROPN, overlap 0.61\n",
      "state 257 aligned with POS PROPN, overlap 0.62\n",
      "state 1018 aligned with POS PROPN, overlap 0.63\n",
      "state 977 aligned with POS PROPN, overlap 0.55\n"
     ]
    }
   ],
   "source": [
    "# calculate coverage\n",
    "# TODO: change vocabulary based matching to occurance based matching\n",
    "# Q: why no alignment with ADV?\n",
    "\n",
    "alignment = {}\n",
    "thres = 0.5\n",
    "covered_pos = []\n",
    "aligned_states = 0\n",
    "for s in state_dominate_set_gpt_token:\n",
    "    for p in pos_dominate_set:\n",
    "        overlap = state_dominate_set_gpt_token[s].intersection(pos_dominate_set[p])\n",
    "        overlap = len(overlap) / float(len(state_dominate_set_gpt_token[s]))\n",
    "        if(overlap > thres):\n",
    "            print('state %s aligned with POS %s, overlap %.2f' % (s, p, overlap))\n",
    "            covered_pos.append(p)\n",
    "            aligned_states += 1\n",
    "            if(p not in alignment): alignment[p] = [s]\n",
    "            else: alignment[p].append(s)\n",
    "covered_pos = set(covered_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "particular-demographic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237\n"
     ]
    }
   ],
   "source": [
    "print(aligned_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-multimedia",
   "metadata": {},
   "source": [
    "**This is to say, with the dominate word set measurement, there are 237 out of 2000 states align with pre-defined POS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-hudson",
   "metadata": {},
   "source": [
    "## Implementation of word occurrence alignment, note that this might be a distribution shift problem here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
